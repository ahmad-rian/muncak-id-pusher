# artillery.yaml - Load Testing untuk Live Cam dengan Pusher
# Testing Real-Time WebSocket Performance

config:
  target: "https://pusher.muncak.id" # Ganti dengan URL Anda
  phases:
    # Warm-up phase
    - duration: 60
      arrivalRate: 5
      name: "Warm-up Phase"

    # Ramp-up phase
    - duration: 120
      arrivalRate: 10
      rampTo: 50
      name: "Ramp-up Phase"

    # Peak load phase
    - duration: 180
      arrivalRate: 100
      name: "Peak Load Phase"

    # Sustained load phase
    - duration: 240
      arrivalRate: 75
      name: "Sustained Load Phase"

    # Stress test phase
    - duration: 120
      arrivalRate: 150
      name: "Stress Test Phase"

  plugins:
    expect: {}
    metrics-by-endpoint: {}

  variables:
    streamSlug:
      - "gunung-rinjani"
      - "gunung-semeru"
      - "gunung-bromo"
    pusherKey: "81f8af2b6681fa8ada90"
    pusherCluster: "ap1"

  payload:
    path: "./test-data/chat-messages.csv"
    fields:
      - "message"
    order: "sequence"
    skipHeader: true

  processor: "./test-processor.js"

  ensure:
    maxErrorRate: 1
    p95: 2000
    p99: 5000

scenarios:
  # Scenario 1: Viewer menonton stream
  - name: "Viewer - Watch Stream"
    weight: 50
    flow:
      - get:
          url: "/live-cam"
          expect:
            - statusCode: 200
          afterResponse: "captureLoadTime"

      - get:
          url: "/live-cam/{{ streamSlug }}"
          expect:
            - statusCode: 200
          afterResponse: "recordPageLoad"

      - think: 2

      # Connect to Pusher
      - function: "connectPusher"

      # Subscribe to stream channel
      - function: "subscribeToStream"

      # Watch stream 30-90 detik
      - think:
          min: 30
          max: 90

      # Simulate chunk loading
      - loop:
          count: 5
          flow:
            - get:
                url: "/live-cam/{{ streamSlug }}/chunk/{{ $loopCount }}"
                expect:
                  - statusCode: [200, 404]
                afterResponse: "recordChunkLatency"
            - think: 3

      - function: "disconnectPusher"

  # Scenario 2: Viewer dengan chat
  - name: "Viewer - Watch & Chat"
    weight: 30
    flow:
      - get:
          url: "/live-cam/{{ streamSlug }}"
          expect:
            - statusCode: 200

      - think: 2
      - function: "connectPusher"
      - function: "subscribeToStream"

      # Load chat history
      - get:
          url: "/live-cam/{{ streamSlug }}/chat-history"
          expect:
            - statusCode: 200
          afterResponse: "recordChatHistoryLoad"

      # Send chat messages
      - loop:
          count: 5
          flow:
            - post:
                url: "/live-cam/{{ streamSlug }}/chat"
                json:
                  username: "Guest-{{ $randomString(8) }}"
                  message: "{{ message }}"
                expect:
                  - statusCode: [200, 429]
                afterResponse: "recordChatLatency"
            - think:
                min: 3
                max: 5

      - think: 30
      - function: "disconnectPusher"

  # Scenario 3: High churn - rapid join/leave
  - name: "High Churn - Join/Leave"
    weight: 15
    flow:
      - get:
          url: "/live-cam/{{ streamSlug }}"

      - function: "connectPusher"
      - function: "subscribeToStream"

      # Stay only 5-15 seconds
      - think:
          min: 5
          max: 15

      - function: "disconnectPusher"

  # Scenario 4: Mirror state testing
  - name: "Mirror State Sync Test"
    weight: 5
    flow:
      - get:
          url: "/live-cam/{{ streamSlug }}"

      - function: "connectPusher"
      - function: "subscribeToStream"
      - function: "subscribeToMirrorState"

      # Monitor mirror state changes
      - think: 60

      - function: "disconnectPusher"

# Custom metrics
metrics:
  - name: "pusher.connect.latency"
    description: "Time to establish Pusher connection"

  - name: "pusher.subscribe.latency"
    description: "Time to subscribe to channel"

  - name: "chunk.load.latency"
    description: "Time to load video chunk"

  - name: "chat.send.latency"
    description: "Time to send chat message"

  - name: "chat.history.latency"
    description: "Time to load chat history"

  - name: "mirror.state.latency"
    description: "Time for mirror state sync"

  - name: "concurrent.connections"
    description: "Number of concurrent Pusher connections"

before:
  flow:
    - function: "setupMonitoring"
    - log: "Starting Pusher load test"

after:
  flow:
    - function: "collectMetrics"
    - function: "generateReport"
    - log: "Load test completed"

expectations:
  - name: "Pusher connection under 500ms"
    condition: "pusher.connect.latency.p95 < 500"

  - name: "Subscribe under 200ms"
    condition: "pusher.subscribe.latency.p95 < 200"

  - name: "Chunk load under 1s"
    condition: "chunk.load.latency.p95 < 1000"

  - name: "Chat message under 300ms"
    condition: "chat.send.latency.p95 < 300"

  - name: "Chat history under 500ms"
    condition: "chat.history.latency.p95 < 500"

  - name: "Support 1000+ concurrent viewers"
    condition: "concurrent.connections.max > 1000"
